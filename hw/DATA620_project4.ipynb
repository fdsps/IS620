{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA620 Project 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answering 6.10 exercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import sklearn as sk\n",
    "from nltk.corpus import movie_reviews\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract top 2000 words in all movie reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'sucess',\n",
       " u'sonja',\n",
       " u'askew',\n",
       " u'woods',\n",
       " u'spiders',\n",
       " u'bazooms',\n",
       " u'hanging',\n",
       " u'francesca',\n",
       " u'comically',\n",
       " u'localized']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = movie_reviews.words()\n",
    "all_words = nltk.FreqDist(w.lower() for w in words)\n",
    "word_features = all_words.keys()[:2000] # more than 2000 words yields very slow training\n",
    "\n",
    "word_features[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract list of words and overall classification (pos/neg) from each review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([u'plot', u':', u'two', u'teen', u'couples'], u'neg')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]\n",
    "(documents[0][0][:5], documents[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create feature set and class for each review against list of 2000 top words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def document_features(document): \n",
    "    document_words = set(document) \n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features\n",
    "\n",
    "featuresets = [(document_features(d), c) for (d,c) in documents] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_set, test_set = featuresets[100:], featuresets[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes classifier..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(212)\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "30 most informative features from training classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "          contains(sans) = True              neg : pos    =     10.0 : 1.0\n",
      "    contains(mediocrity) = True              neg : pos    =      8.5 : 1.0\n",
      "         contains(wires) = True              neg : pos    =      7.0 : 1.0\n",
      "          contains(hugo) = True              pos : neg    =      6.9 : 1.0\n",
      "     contains(dismissed) = True              pos : neg    =      6.3 : 1.0\n",
      "   contains(bruckheimer) = True              neg : pos    =      6.3 : 1.0\n",
      "        contains(fabric) = True              pos : neg    =      5.7 : 1.0\n",
      "   contains(overwhelmed) = True              pos : neg    =      5.7 : 1.0\n",
      "   contains(understands) = True              pos : neg    =      5.6 : 1.0\n",
      "           contains(ugh) = True              neg : pos    =      5.6 : 1.0\n",
      "     contains(uplifting) = True              pos : neg    =      5.5 : 1.0\n",
      "        contains(doubts) = True              pos : neg    =      5.2 : 1.0\n",
      "         contains(tripe) = True              neg : pos    =      5.1 : 1.0\n",
      "  contains(accomplishes) = True              pos : neg    =      5.1 : 1.0\n",
      "       contains(topping) = True              pos : neg    =      5.1 : 1.0\n",
      "          contains(wits) = True              pos : neg    =      5.1 : 1.0\n",
      "          contains(lang) = True              pos : neg    =      5.1 : 1.0\n",
      "  contains(effortlessly) = True              pos : neg    =      5.0 : 1.0\n",
      "       contains(quicker) = True              neg : pos    =      4.8 : 1.0\n",
      "         contains(locks) = True              neg : pos    =      4.8 : 1.0\n",
      "     contains(testament) = True              pos : neg    =      4.5 : 1.0\n",
      "           contains(wcw) = True              neg : pos    =      4.1 : 1.0\n",
      "       contains(maxwell) = True              neg : pos    =      4.1 : 1.0\n",
      "      contains(squabble) = True              neg : pos    =      4.1 : 1.0\n",
      "        contains(minnie) = True              pos : neg    =      4.0 : 1.0\n",
      "      contains(matheson) = True              pos : neg    =      3.9 : 1.0\n",
      "          contains(leia) = True              pos : neg    =      3.9 : 1.0\n",
      "         contains(spins) = True              pos : neg    =      3.9 : 1.0\n",
      "            contains(33) = True              pos : neg    =      3.9 : 1.0\n",
      "          contains(wang) = True              pos : neg    =      3.9 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mediocrity | negative  \n",
    "Ugh | negative  \n",
    "Uplifting | positive  \n",
    "Accomplishes | positive: typically used in a positive sense.  \n",
    "Effortlessly | positive: usually a positive descriptor.  \n",
    "Leia | positive: who doesn't like Princess Leia?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Surprising**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sans | negative: 'without' is not necessarily negative.  \n",
    "Wires | negative: as in surveillance?  \n",
    "Hugo | positive: I guess characters named Hugo are generally relatable. \n",
    "Bruckheimer | negative: I don't know--I live some of his films.  \n",
    "Fabric | positive: huh?  \n",
    "Doubts | positive  \n",
    "Quicker | negative  \n",
    "Wcw | negative: ?  \n",
    "Minnie | positive: Minnie is a sweet name.  \n",
    "Wang | positive: not touching this one."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
